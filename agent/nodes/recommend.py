"""
ëŒ€ì‘ ë°©ì•ˆ ìƒì„± ë…¸ë“œ

ì—­í• :
- LLMì„ ì‚¬ìš©í•˜ì—¬ ì¢…í•© ë¶„ì„ ë° ëŒ€ì‘ ë°©ì•ˆ ìƒì„±
- ì‚¬ìš©ì ì¹œí™”ì ì¸ ì¡°ì–¸ ì œê³µ
- ê¸°ì¡´ scam_defense.pyì˜ _generate_unified_answer() ë¡œì§ í™œìš©
"""

from typing import Dict, List, Optional
from agent.state import AgentState
from langchain_core.documents import Document


# ë¬¸ì„œ í¬ë§¤íŒ… ìœ í‹¸ë¦¬í‹°
def format_documents(documents: List[Document], max_docs: int = 5) -> str:
    """
    ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ í…ìŠ¤íŠ¸ë¡œ í¬ë§¤íŒ…

    Args:
        documents: ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        max_docs: ìµœëŒ€ ë¬¸ì„œ ìˆ˜

    Returns:
        í¬ë§¤íŒ…ëœ í…ìŠ¤íŠ¸
    """
    if not documents:
        return "ê´€ë ¨ì •ë³´ ì—†ìŒ"

    formatted = []
    for idx, doc in enumerate(documents[:max_docs], 1):
        meta = doc.metadata or {}

        label = (
            meta.get("scam_type")
            or meta.get("source")
            or meta.get("title")
            or f"ë¬¸ì„œ{idx}"
        )
        content = doc.page_content.strip()[:200]  # ìµœëŒ€200
        formatted.append(f"[{label}] {content}")

    return "\n\n".join(formatted)


def format_pattern_analysis(
    matched_patterns: List[Dict], risk_level: str, risk_score: int
) -> str:
    """
    íŒ¨í„´ ë¶„ì„ ê²°ê³¼ í¬ë§¤íŒ…

    Args:
        matched_patterns: ë§¤ì¹­ëœ íŒ¨í„´
        risk_level: ìœ„í—˜ë„ ë ˆë²¨
        risk_score: ìœ„í—˜ë„ ì ìˆ˜

    Returns:
        í¬ë§¤íŒ…ëœ í…ìŠ¤íŠ¸
    """
    if not matched_patterns:
        return "ë§¤ì¹­ëœ íŒ¨í„´ ì—†ìŒ"

    lines = [f"ìœ„í—˜ë„: {risk_level} ({risk_score}ì )\n"]

    lines.append("ë§¤ì¹­ëœ ì‚¬ê¸°ìœ í˜•:")
    for pattern in matched_patterns[:5]:
        scam_type = pattern.get("scam_type", "ì•Œ ìˆ˜ ì—†ìŒ")
        danger = pattern.get("danger_level", "ì •ë³´")
        keywords = pattern.get("matched_patterns", [])

        kw_str = ", ".join(keywords[:3]) if keywords else "N/A"
        lines.append(f"- {scam_type} ({danger}): {kw_str}")
    return "\n".join(lines)


# LLMí”„ë¡¬í¬íŠ¸
UNIFIED_SYSTEM_PROMPT = """
ë„ˆëŠ” ê¸ˆìœµì‚¬ê¸° ë°©ì§€ ì „ë¬¸ ìƒë‹´ì‚¬ë‹¤.
ì œê³µëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ëª…í™•í•˜ê³  ì‹¤ìš©ì ì¸ ëŒ€ì‘ ê°€ì´ë“œë¥¼ ì‘ì„±í•˜ë¼.

ë‹µë³€ êµ¬ì„±:
1. ì‚¬ê¸° ì—¬ë¶€ íŒë‹¨ ë° ìœ„í—˜ë„ í‰ê°€
2. ì‚¬ê¸° ìœ í˜• ë° ìˆ˜ë²• ì„¤ëª…
3. ì¦‰ì‹œ í•´ì•¼ í•  ëŒ€ì‘ ë°©ë²• (ìš°ì„ ìˆœìœ„ë³„ ë²ˆí˜¸ ëª©ë¡)
4. ì ˆëŒ€ í•˜ì§€ ë§ì•„ì•¼ í•  í–‰ë™ (ë²ˆí˜¸ ëª©ë¡)
5. ì‹ ê³  ë°©ë²• ë° ì—°ë½ì²˜
6. ì˜ˆë°© íŒ ë° ì£¼ì˜ì‚¬í•­

ë‹µë³€ í˜•ì‹:
- ìœ„í—˜ë„ ì•„ì´ì½˜ ì‚¬ìš© (ğŸš¨ ë§¤ìš°ìœ„í—˜, âš ï¸ ìœ„í—˜, âš¡ ì£¼ì˜, â„¹ï¸ ì•ˆì „)
- ëª…í™•í•˜ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì–¸
- ì´í•´í•˜ê¸° ì‰¬ìš´ ì–¸ì–´ ì‚¬ìš©
- ì´ëª¨ì§€ í™œìš©í•˜ì—¬ ê°€ë…ì„± í–¥ìƒ

ì •í™•í•œ ì¶œì²˜ ë¬¸ì„œë¥¼ ê·¼ê±°ë¡œ ë‹µë³€í•˜ë˜, ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ê²½ìš° ì‹ ì¤‘í•œ íƒœë„ë¥¼ ìœ ì§€í•˜ë¼.
"""


def build_llm_prompt(
    message: str,
    sender: Optional[str],
    scam_type: str,
    risk_level: str,
    risk_score: int,
    matched_patterns: List[Dict],
    similar_cases: List[Document],
) -> str:
    """
    LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„±

    Args:
        message: ì˜ì‹¬ ë©”ì‹œì§€
        sender: ë°œì‹ ì
        scam_type: ì‚¬ê¸° ìœ í˜•
        risk_level: ìœ„í—˜ë„ ë ˆë²¨
        risk_score: ìœ„í—˜ë„ ì ìˆ˜
        matched_patterns: ë§¤ì¹­ëœ íŒ¨í„´
        similar_cases: ìœ ì‚¬ ì‚¬ë¡€

    Returns:
        í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸
    """

    # RAG ë¬¸ì„œ
    rag_docs = [
        doc for doc in similar_cases if doc.metadata.get("origin") != "pattern_matching"
    ]

    # íŒ¨í„´ ë¬¸ì„œ (ì‹¤ì‹œê°„ ë§¤ì¹­)
    pattern_docs = [
        doc for doc in similar_cases if doc.metadata.get("origin") == "pattern_matching"
    ]

    prompt = f"""
**ì˜ì‹¬ ë©”ì‹œì§€:**
{message}

**ë°œì‹ ì:** {sender or 'ë¯¸ì œê³µ'}

**ë¶„ì„ ê²°ê³¼:**
- ì‚¬ê¸° ìœ í˜•: {scam_type}
- ìœ„í—˜ë„: {risk_level} ({risk_score}ì )

**ì‹¤ì‹œê°„ íŒ¨í„´ ë¶„ì„:**
{format_pattern_analysis(matched_patterns, risk_level, risk_score)}

**Knowledge Base (ê³¼ê±° ìœ ì‚¬ ì‚¬ë¡€):**
{format_documents(rag_docs, max_docs=3)}

**ì‹¤ì‹œê°„ ì‚¬ê¸° DB ë§¤ì¹­:**
{format_documents(pattern_docs, max_docs=3)}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¦‰ì‹œ ëŒ€ì‘ ê°€ì´ë“œë¥¼ ì‘ì„±í•˜ë¼.
"""

    return prompt


# LLMí˜¸ì¶œ
async def generate_with_llm(
    prompt: str, system_prompt: str = UNIFIED_SYSTEM_PROMPT
) -> str:
    """
    LLMìœ¼ë¡œ ë‹µë³€ ìƒì„±

    Args:
        prompt: ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸
        system_prompt: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸

    Returns:
        ìƒì„±ëœ ë‹µë³€
    """
    try:
        from infrastructure.llm.client import UpstageClient
        from app.config import settings

        # LLM í´ë¼ì´ì–´íŠ¸ ìƒì„±
        llm = UpstageClient(
            api_key=settings.UPSTAGE_API_KEY,
            model=settings.LLM_MODEL,
            temperature=settings.LLM_TEMPERATURE,
        )

        response = await llm.generate(prompt=prompt, system_prompt=system_prompt)

        return response.strip()

    except Exception as e:
        print(f"  âš ï¸ LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")

        # í´ë°± ì‘ë‹µ
        return """
âš ï¸ AI ë¶„ì„ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.

**ê¸´ê¸‰ ìƒë‹´:**
- ê²½ì°°ì²­ ì‚¬ì´ë²„ì•ˆì „êµ­: êµ­ë²ˆì—†ì´ 182
- ê¸ˆìœµê°ë…ì›: 1332
- ì‚¬ì´ë²„ìº… ì•± ë‹¤ìš´ë¡œë“œ

**ê¸°ë³¸ ëŒ€ì‘ ë°©ë²•:**
1. âŒ ì ˆëŒ€ ëˆì„ ë³´ë‚´ì§€ ë§ˆì„¸ìš”
2. âŒ ê°œì¸ì •ë³´ë¥¼ ì œê³µí•˜ì§€ ë§ˆì„¸ìš”
3. âŒ ë§í¬ë¥¼ í´ë¦­í•˜ì§€ ë§ˆì„¸ìš”
4. ğŸ“ ë°œì‹ ì ì°¨ë‹¨
5. ğŸ“± ìŠ¤í¬ë¦°ìƒ· ì €ì¥ í›„ ì‹ ê³ 

ì˜ì‹¬ë˜ëŠ” ë©”ì‹œì§€ëŠ” ë°˜ë“œì‹œ ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ì„¸ìš”.
"""


# ë©”ì¸ ë…¸ë“œ í•¨ìˆ˜
async def recommend_actions(state: AgentState) -> Dict:
    """
    ëŒ€ì‘ ë°©ì•ˆ ìƒì„± ë…¸ë“œ

    LLMì„ ì‚¬ìš©í•˜ì—¬:
    - ì¢…í•© ë¶„ì„
    - ëŒ€ì‘ ë°©ì•ˆ
    - ì‹ ê³  ë°©ë²•

    Args:
        state: ì—ì´ì „íŠ¸ ìƒíƒœ

    Returns:
        ì—…ë°ì´íŠ¸ëœ ìƒíƒœ
    """
    print("\n" + "=" * 60)
    print("ğŸ’¡ [4/4] ëŒ€ì‘ ë°©ì•ˆ ìƒì„± ì¤‘...")
    print("=" * 60)

    # ìƒíƒœì—ì„œ ì •ë³´ ì¶”ì¶œ
    message = state["message"]
    sender = state.get("sender")
    scam_type = state.get("scam_type")
    risk_level = state.get("risk_level", "ì•Œ ìˆ˜ ì—†ìŒ")
    risk_score = state.get("risk_score", 0)
    is_scam = state.get("is_scam", False)
    risk_factors = state.get("risk_factors", [])
    matched_patterns = state.get("matched_patterns", [])
    similar_cases = state.get("similar_cases", [])

    print(f"  â†’ ìœ„í—˜ë„: {risk_level} ({risk_score}ì )")
    print(f"  â†’ ì‚¬ê¸° ì—¬ë¶€: {'ì˜ˆ' if is_scam else 'ì•„ë‹ˆì˜¤'}")

    # LLM í”„ë¡¬í¬íŠ¸êµ¬ì„±
    prompt = build_llm_prompt(
        message=message,
        sender=sender,
        scam_type=scam_type,
        risk_level=risk_level,
        risk_score=risk_score,
        matched_patterns=matched_patterns,
        similar_cases=similar_cases,
    )

    # LLM í˜¸ì¶œ
    print(f"  â†’ LLM í˜¸ì¶œ ì¤‘...")

    analysis = await generate_with_llm(prompt)

    print(f"  â†’ ë¶„ì„ ìƒì„± ì™„ë£Œ ({len(analysis)}ì)")

    # ëŒ€ì‘ ë°©ì•ˆì€ analysisì— í¬í•¨ë˜ì–´ ìˆìŒ
    recommendations = analysis

    # ìƒíƒœ ì—…ë°ì´íŠ¸
    return {"analysis": analysis, "recommendations": recommendations, "completed": True}
